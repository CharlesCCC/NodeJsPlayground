{"version":3,"sources":["index.js"],"names":["App","videoRef","React","createRef","canvasRef","detectFrame","video","model","detect","then","predictions","_this","renderPredictions","requestAnimationFrame","ctx","current","getContext","clearRect","canvas","width","height","font","textBaseline","forEach","prediction","x","bbox","y","strokeStyle","lineWidth","strokeRect","fillStyle","textWidth","measureText","class","textHeight","parseInt","fillRect","fillText","_this2","this","navigator","mediaDevices","getUserMedia","webCamPromise","audio","facingMode","stream","window","srcObject","Promise","resolve","reject","onloadedmetadata","modelPromise","cocoSsd","all","values","catch","error","console","react__WEBPACK_IMPORTED_MODULE_5___default","a","createElement","className","autoPlay","playsInline","muted","ref","Component","rootElement","document","getElementById","ReactDOM","render"],"mappings":"wRAOMA,0NACJC,SAAWC,IAAMC,cACjBC,UAAYF,IAAMC,cA+BlBE,YAAc,SAACC,EAAOC,GACpBA,EAAMC,OAAOF,GAAOG,KAAK,SAAAC,GACvBC,EAAKC,kBAAkBF,GACvBG,sBAAsB,WACpBF,EAAKN,YAAYC,EAAOC,UAK9BK,kBAAoB,SAAAF,GAClB,IAAMI,EAAMH,EAAKP,UAAUW,QAAQC,WAAW,MAC9CF,EAAIG,UAAU,EAAG,EAAGH,EAAII,OAAOC,MAAOL,EAAII,OAAOE,QAEjD,IAAMC,EAAO,kBACbP,EAAIO,KAAOA,EACXP,EAAIQ,aAAe,MACnBZ,EAAYa,QAAQ,SAAAC,GAClB,IAAMC,EAAID,EAAWE,KAAK,GACpBC,EAAIH,EAAWE,KAAK,GACpBP,EAAQK,EAAWE,KAAK,GACxBN,EAASI,EAAWE,KAAK,GAE/BZ,EAAIc,YAAc,UAClBd,EAAIe,UAAY,EAChBf,EAAIgB,WAAWL,EAAGE,EAAGR,EAAOC,GAE5BN,EAAIiB,UAAY,UAChB,IAAMC,EAAYlB,EAAImB,YAAYT,EAAWU,OAAOf,MAC9CgB,EAAaC,SAASf,EAAM,IAClCP,EAAIuB,SAASZ,EAAGE,EAAGK,EAAY,EAAGG,EAAa,KAGjDzB,EAAYa,QAAQ,SAAAC,GAClB,IAAMC,EAAID,EAAWE,KAAK,GACpBC,EAAIH,EAAWE,KAAK,GAE1BZ,EAAIiB,UAAY,UAChBjB,EAAIwB,SAASd,EAAWU,MAAOT,EAAGE,yFAlElB,IAAAY,EAAAC,KAClB,GAAIC,UAAUC,cAAgBD,UAAUC,aAAaC,aAAc,CACjE,IAAMC,EAAgBH,UAAUC,aAC7BC,aAAa,CACZE,OAAO,EACPvC,MAAO,CACLwC,WAAY,UAGfrC,KAAK,SAAAsC,GAGJ,OAFAC,OAAOD,OAASA,EAChBR,EAAKtC,SAASc,QAAQkC,UAAYF,EAC3B,IAAIG,QAAQ,SAACC,EAASC,GAC3Bb,EAAKtC,SAASc,QAAQsC,iBAAmB,WACvCF,SAIFG,EAAeC,MACrBL,QAAQM,IAAI,CAACF,EAAcV,IACxBnC,KAAK,SAAAgD,GACJlB,EAAKlC,YAAYkC,EAAKtC,SAASc,QAAS0C,EAAO,MAEhDC,MAAM,SAAAC,GACLC,QAAQD,MAAMA,uCA+CpB,OACEE,EAAAC,EAAAC,cAAA,WACEF,EAAAC,EAAAC,cAAA,SACEC,UAAU,OACVC,UAAQ,EACRC,aAAW,EACXC,OAAK,EACLC,IAAK5B,KAAKvC,SACVkB,MAAM,MACNC,OAAO,QAETyC,EAAAC,EAAAC,cAAA,UACEC,UAAU,OACVI,IAAK5B,KAAKpC,UACVe,MAAM,MACNC,OAAO,gBA1FClB,IAAMmE,YAiGlBC,EAAcC,SAASC,eAAe,QAC5CC,IAASC,OAAOb,EAAAC,EAAAC,cAAC/D,EAAD,MAASsE","file":"static/js/main.d6af01f7.chunk.js","sourcesContent":["import React from \"react\";\r\nimport ReactDOM from \"react-dom\";\r\n\r\nimport * as cocoSsd from \"@tensorflow-models/coco-ssd\";\r\nimport \"@tensorflow/tfjs\";\r\nimport \"./styles.css\";\r\n\r\nclass App extends React.Component {\r\n  videoRef = React.createRef();\r\n  canvasRef = React.createRef();\r\n\r\n  componentDidMount() {\r\n    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\r\n      const webCamPromise = navigator.mediaDevices\r\n        .getUserMedia({\r\n          audio: false,\r\n          video: {\r\n            facingMode: \"user\"\r\n          }\r\n        })\r\n        .then(stream => {\r\n          window.stream = stream;\r\n          this.videoRef.current.srcObject = stream;\r\n          return new Promise((resolve, reject) => {\r\n            this.videoRef.current.onloadedmetadata = () => {\r\n              resolve();\r\n            };\r\n          });\r\n        });\r\n      const modelPromise = cocoSsd.load();\r\n      Promise.all([modelPromise, webCamPromise])\r\n        .then(values => {\r\n          this.detectFrame(this.videoRef.current, values[0]);\r\n        })\r\n        .catch(error => {\r\n          console.error(error);\r\n        });\r\n    }\r\n  }\r\n\r\n  detectFrame = (video, model) => {\r\n    model.detect(video).then(predictions => {\r\n      this.renderPredictions(predictions);\r\n      requestAnimationFrame(() => {\r\n        this.detectFrame(video, model);\r\n      });\r\n    });\r\n  };\r\n\r\n  renderPredictions = predictions => {\r\n    const ctx = this.canvasRef.current.getContext(\"2d\");\r\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\r\n    // Font options.\r\n    const font = \"16px sans-serif\";\r\n    ctx.font = font;\r\n    ctx.textBaseline = \"top\";\r\n    predictions.forEach(prediction => {\r\n      const x = prediction.bbox[0];\r\n      const y = prediction.bbox[1];\r\n      const width = prediction.bbox[2];\r\n      const height = prediction.bbox[3];\r\n      // Draw the bounding box.\r\n      ctx.strokeStyle = \"#00FFFF\";\r\n      ctx.lineWidth = 4;\r\n      ctx.strokeRect(x, y, width, height);\r\n      // Draw the label background.\r\n      ctx.fillStyle = \"#00FFFF\";\r\n      const textWidth = ctx.measureText(prediction.class).width;\r\n      const textHeight = parseInt(font, 10); // base 10\r\n      ctx.fillRect(x, y, textWidth + 4, textHeight + 4);\r\n    });\r\n\r\n    predictions.forEach(prediction => {\r\n      const x = prediction.bbox[0];\r\n      const y = prediction.bbox[1];\r\n      // Draw the text last to ensure it's on top.\r\n      ctx.fillStyle = \"#000000\";\r\n      ctx.fillText(prediction.class, x, y);\r\n    });\r\n  };\r\n\r\n  render() {\r\n    return (\r\n      <div>\r\n        <video\r\n          className=\"size\"\r\n          autoPlay\r\n          playsInline\r\n          muted\r\n          ref={this.videoRef}\r\n          width=\"600\"\r\n          height=\"500\"\r\n        />\r\n        <canvas\r\n          className=\"size\"\r\n          ref={this.canvasRef}\r\n          width=\"600\"\r\n          height=\"500\"\r\n        />\r\n      </div>\r\n    );\r\n  }\r\n}\r\n\r\nconst rootElement = document.getElementById(\"root\");\r\nReactDOM.render(<App />, rootElement);\r\n"],"sourceRoot":""}